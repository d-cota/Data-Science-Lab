{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% benchmark\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from time import time\n",
    "\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sparse_cg\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=50),\n",
    "         \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n",
    "                                       tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=.1)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "indices = np.arange(len(results))\n",
    "results.sort(key=lambda tup: tup[1])\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Different classifiers score\")\n",
    "plt.barh(indices, score, .2, label=\"Accuracy\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.savefig(IMAGE_PATH + 'classifiers')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% plot score\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "tokenizer = LemmaTokenizer()\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenizer, stop_words=stopwords, ngram_range=(1,2), min_df=3)\n",
    "X_tfidf = vectorizer.fit_transform(training_set['full_text'])\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "svd = TruncatedSVD(n_components=700, random_state=42)\n",
    "X_svd = svd.fit_transform(X_tfidf)\n",
    "\n",
    "print(f\"Total variance explained: {np.sum(svd.explained_variance_ratio_):.2f}\")\n",
    "\n",
    "\n",
    "word_positions = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "cluster_ids = generate_wordclouds(X_svd, X_tfidf, 2, word_positions)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, training_set['class'],test_size=0.2, random_state=42)\n",
    "clf = SGDClassifier(verbose=2, tol=0.0001, alpha=0.00007, loss='modified_huber')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "\n",
    "clf = LinearSVC(C=0.9, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)'''\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(tokenizer=LemmaTokenizer())),\n",
    "    ('clf', ClfSwitcher()),\n",
    "])\n",
    "\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'clf__estimator': [RidgeClassifier(solver='auto', random_state=42)], # SVM if hinge loss / logreg if log loss\n",
    "        \"tfidf__min_df\" : [3, 5, 10, 20],\n",
    "        'clf__estimator__alpha': [1.0, 0.1, 0.01],\n",
    "        'clf__estimator__tol': [1e-2, 1e-3, 1e-4],\n",
    "    },\n",
    "    {\n",
    "        'clf__estimator': [MultinomialNB()],\n",
    "        \"tfidf__min_df\" : [3, 5, 10, 20],\n",
    "        'clf__estimator__alpha': (1, 1e-1, 1e-2, 1e-3),\n",
    "    },\n",
    "    {\n",
    "        'clf__estimator': [LinearSVC(dual=False, random_state=42)],\n",
    "        \"tfidf__min_df\" : [3, 5, 10, 20],\n",
    "        'clf__estimator__tol': [1e-2, 1e-3, 1e-4],\n",
    "        'clf__estimator__penalty': ('l2', 'l1'),\n",
    "        'clf__estimator__C': [1, 1e-1, 1e-2, 1e-3],\n",
    "    },\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, return_train_score=False, verbose=3)\n",
    "gscv.fit(training_set['full_text'], training_set['class'])\n",
    "\n",
    "gscv.cv_results_\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "{\n",
    "        'clf__estimator': [RidgeClassifier(solver='auto', random_state=42)], # SVM if hinge loss / logreg if log loss\n",
    "        \"tfidf__min_df\" : [1, 3],\n",
    "        \"tfidf__stopwords\" : (None, stopwords),\n",
    "        \"tfidf__ngram_range\" : [(1,1), (1,2)],\n",
    "        'clf__estimator__alpha': [1.0, 1.5, 2.0],\n",
    "        'clf__estimator__tol': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    },\n",
    "     {\n",
    "        'clf__estimator': [SGDClassifier(random_state=42, verbose=3)],\n",
    "        \"tfidf__min_df\" : [1],\n",
    "        \"tfidf__stop_words\" : [None],\n",
    "        \"tfidf__ngram_range\" : [(1,2)],\n",
    "        'clf__estimator__tol': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "        'clf__estimator__alpha': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "        'clf__estimator__loss': ('hinge', 'modified_huber'),\n",
    "    },\n",
    "        {\n",
    "        'clf__estimator': [PassiveAggressiveClassifier(random_state=42)], # SVM if hinge loss / logreg if log loss\n",
    "        \"tfidf__min_df\" : [1],\n",
    "        \"tfidf__stop_words\" : [None],\n",
    "        \"tfidf__ngram_range\" : [(1,2)],\n",
    "        'clf__estimator__C': [0.5, 1.0, 1.5, 2.0],\n",
    "        'clf__estimator__tol': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    },\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", CountVectorizer(tokenizer=LemmaTokenizer(), binary=True)),\n",
    "    ('clf', ClfSwitcher()),\n",
    "])\n",
    "\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'clf__estimator': [BernoulliNB()], # SVM if hinge loss / logreg if log loss\n",
    "        \"tfidf__min_df\" : [1],\n",
    "        \"tfidf__stop_words\" : [None],\n",
    "        \"tfidf__ngram_range\" : [(1,2)],\n",
    "        'clf__estimator__alpha': [0.1, 0.3, 0.6, 1.0],\n",
    "    },\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}