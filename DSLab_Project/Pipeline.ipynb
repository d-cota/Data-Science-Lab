{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier, Perceptron, PassiveAggressiveClassifier, LinearRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.base import BaseEstimator\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "FEATURE_LIST = ['created_at', 'id', 'full_text', 'user', 'retweet_count', 'favorite_count', 'coordinates', 'place', 'class']\n",
    "N_BINS = 18\n",
    "IMAGE_PATH = 'images/'\n",
    "RESULTS_PATH = 'results/'\n",
    "SUBMISSIONS_PATH = 'submissions/'\n",
    "\n",
    "stopwords = sw.words('english') + [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'doe', 'ha', \"n't\", 'sha', 'wa', 'wo']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.tokenizer = TweetTokenizer()\n",
    "\n",
    "    def __call__(self, document):\n",
    "        lemmas = []\n",
    "\n",
    "        for t in self.tokenizer.tokenize(document):\n",
    "            t.strip()\n",
    "            lemma = self.lemmatizer.lemmatize(t)\n",
    "\n",
    "            # remove tokens with only punctuation\n",
    "            if lemma not in string.punctuation:\n",
    "                lemmas.append(lemma)\n",
    "\n",
    "        return lemmas\n",
    "\n",
    "class ClfSwitcher(BaseEstimator):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator = SGDClassifier(),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A Custom BaseEstimator that can switch between classifiers.\n",
    "        :param estimator: sklearn object - The classifier\n",
    "        \"\"\"\n",
    "\n",
    "        self.estimator = estimator\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.estimator.score(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "training_set = pd.read_json('development.jsonl', lines=True)\n",
    "training_set = training_set[FEATURE_LIST]\n",
    "\n",
    "test_set = pd.read_json('evaluation.jsonl', lines=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "tweets = training_set[\"full_text\"].tolist()\n",
    "desc_list = [item['description'] for item in training_set[\"user\"]]\n",
    "\n",
    "test_tweets = test_set[\"full_text\"].tolist()\n",
    "test_desc_list = [item['description'] for item in test_set[\"user\"]]\n",
    "\n",
    "train_len = [len(t) for t in tweets]\n",
    "test_len = [len(t) for t in tweets]\n",
    "\n",
    "train_len = np.array(train_len).reshape(-1,1)\n",
    "test_len = np.array(test_len).reshape(-1,1)\n",
    "\n",
    "disc_len = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='quantile')\n",
    "\n",
    "X_train_len = disc_len.fit_transform(train_len)\n",
    "X_test_len = disc_len.transform(test_len)\n",
    "\n",
    "X_train_len = np.array_str(X_train_len.astype(int))\n",
    "X_test_len = np.array_str(X_test_len.astype(int))\n",
    "\n",
    "X_train = [' '.join(z) for z in zip(tweets, desc_list)]\n",
    "X_test = [' '.join(z) for z in zip(test_tweets, test_desc_list)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(tokenizer=LemmaTokenizer(), binary=True)),\n",
    "    ('clf', ClfSwitcher()),\n",
    "])\n",
    "\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        \"tfidf__min_df\" : [1],\n",
    "        \"tfidf__ngram_range\" : [(1,4)],\n",
    "        'clf__estimator': [SGDClassifier(random_state=42)],\n",
    "        'clf__estimator__tol': [1e-3],\n",
    "        'clf__estimator__alpha': [1e-5],\n",
    "        'clf__estimator__loss': ['hinge'],\n",
    "    },\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, return_train_score=False, verbose=5)\n",
    "gscv.fit(X_train, training_set['class'])\n",
    "\n",
    "gscv.cv_results_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# TODO function wrapper\n",
    "\n",
    "results = pd.DataFrame(gscv.cv_results_)\n",
    "results = results[['param_clf__estimator','param_clf__estimator__alpha','param_clf__estimator__tol','param_clf__estimator__loss','param_tfidf__min_df',\t'param_tfidf__ngram_range','mean_test_score']]\n",
    "results = results.sort_values(by=['mean_test_score'], ascending=False)\n",
    "\n",
    "results.to_excel(\"results_pipeline_SGDdesc#2.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "\n",
    "## TODO function wrapper\n",
    "predictions = gscv.predict(X_test)\n",
    "pred = pd.DataFrame()\n",
    "pred.insert(0, \"Predicted\", predictions, True)\n",
    "\n",
    "pred.to_csv('submission_SGDdesc#2.csv',sep=',', index_label='Id')\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}